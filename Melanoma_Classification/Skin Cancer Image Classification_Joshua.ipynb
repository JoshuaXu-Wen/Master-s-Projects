{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c7cad155-0784-4d08-aec9-34223ffaaf40",
    "_uuid": "aaee4aa4-63e7-47ec-b231-94ab27972c79",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6797b6f5-0c75-4f88-a281-5c992bd52921",
    "_uuid": "88b4a885-6332-423a-837c-2cdb5a0bcea2"
   },
   "outputs": [],
   "source": [
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "013fd77c-f3bf-4206-9346-0854a20cdf8b",
    "_uuid": "ffb9ce2e-534b-4e51-8663-2828f4691a93",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "74b07eda-86b9-4689-ac13-a22e8b89d86d",
    "_uuid": "3a2a34f4-4b8f-40af-b988-283ad7b93de6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb278b12-cf8a-41dd-8d88-3b184b2ee90b",
    "_uuid": "33563630-2324-4201-8b9c-aed93e2a7092",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11813cbc-87c3-432b-92cf-f6c19d9a3cc7",
    "_uuid": "40672c3a-0fed-4bf3-9db7-678eb413e553",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e4e8e689-5b1a-4d5b-9bf1-4ab909920d99",
    "_uuid": "9d5edd97-2135-4247-b9de-b2e88ec32bfe",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0450c254-685a-4fc4-8d4b-5ce2f3925fb6",
    "_uuid": "42c662ab-5f35-4624-a022-d1862f1207ab",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "424a594d-fe22-4368-82c0-a7f8728e01e2",
    "_uuid": "32d2fb49-cf0b-496b-a891-d2eff62e0f44"
   },
   "source": [
    "## Insight\n",
    "1. Missing vaules\n",
    "\n",
    "Both metadata and image files show the the total number of train images is 33126. In metadata, some columns has some missing values (NaN), namely sex, age_approx and anatom_site_general_challenge.\n",
    "On the other hand, only \"anatom_site_general_challenge\" in the test data has missing values.\n",
    "\n",
    "Handling missing values will be done before model building and training. Several choices we can choose (drop or fill values), but before we make decision, let's acquire more detail about the columns first.\n",
    "\n",
    "2. Unique values\n",
    "    \n",
    "    1) one patient may have muliple images in the datasets.\n",
    " \n",
    "    2) \"benign_malignant\" and \"target\" are both binary classification, they are what we need to predict, thus, \"benign_malignant\" should not be included in features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c8847f53-1fe4-4d2a-ae8d-3ab87107c4bd",
    "_uuid": "fc6854fe-6689-4d2e-89cb-31e720a69e07"
   },
   "source": [
    "## target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "07b0d664-d0e3-4f58-97ec-89e571a66c58",
    "_uuid": "24864f07-22e5-43b4-be1c-939b1e38bcb8"
   },
   "outputs": [],
   "source": [
    "sns.countplot(train_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ece2d811-6a73-4a46-a88f-5b66aa734cc3",
    "_uuid": "24b33b97-aceb-461e-a2d6-92273ae4530f"
   },
   "source": [
    "## Insight\n",
    "* This step helps us to find out the target values (Y values) distribution.\n",
    "\n",
    "* the classification of this datasets is binary - it has shown by the nunique function, it is worthy to note that the distribution of target values in training sample is extremely imbalance: 99% of the target value is zero. \n",
    "\n",
    "* This extreme imbalance of Y values may cause a dilemma：\n",
    "    * you will get a good validating accuracy, (validation dataset is a randomly selected subset of training dataset, it is reasonable to assume that randomly guess may get >90% accuracy), but the test datasets may differ from the traning dataset and the test accuracy is low;\n",
    "    * or you will get both high validating accuracy and test accuracy - the problem is any algorithm will do the same thing.\n",
    "    * the real problem is that it makes more hard to identify malignant melanoma, because the corresponding samples are too few to identify features. \n",
    "* Therefore, having too many benign samples does not help us to identify maliganant melanoma. This may imply that we could reduce benign samples to reduce overfitting issue. And we will reduce benign samples in training sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "206b5272-8968-4a04-9233-c7a20c25842c",
    "_uuid": "e7c6b02f-45f4-4c16-bdcb-63e64fd58c2c"
   },
   "source": [
    "## Age,Sex and melanoma distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aff875a9-73ff-4900-a702-9569feeb5e71",
    "_uuid": "8ca25633-0d4e-4721-94b9-34b98dbaced8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(16,8), sharex=True)\n",
    "\n",
    "cond1 = train_df.benign_malignant == 'benign'\n",
    "cond2 = train_df.benign_malignant == 'malignant'\n",
    "#sns.countplot('age_approx',hue='sex', data=train_df)\n",
    "#sns.barplot('age_approx', 'target', 'sex', data=train_df)\n",
    "sns.countplot(train_df['age_approx'].where(cond1), hue=train_df.sex, ax=ax[0])\n",
    "ax[0].set_title(\"Benign cases among genders in train dataset\", pad=10)\n",
    "\n",
    "sns.countplot(train_df['age_approx'].where(cond2), hue=train_df.sex, ax=ax[1])\n",
    "ax[1].set_title(\"Malignant cases among genders in train dataset\", pad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "40a49be0-86b3-40ab-919a-48e330ac8cd9",
    "_uuid": "bd70020d-ee94-4948-ad44-5f5dbe65b63d"
   },
   "source": [
    "## Insight\n",
    "* It is obvious that age plays a key role in melanoma diagnoses. Males in (60,75) seems to be risky in malignant tumor while Females in 55 and 65 are the most risky group.\n",
    "\n",
    "* As for sex, it seems that males have more risk than females to have malignant tumor.\n",
    " \n",
    "* It also noticable that males in (45,50) have a relatively high potential of developing a malignant tumor. We could speculate that besides age and sex, there would be other effects cause the high ratios for males in such early ages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7ecb216c-07e5-497c-9b1e-5b5047b967a3",
    "_uuid": "e9f7ab9d-5ac9-42fb-b3a0-0fe204133245"
   },
   "source": [
    "## Anatom site distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45ae067e-d68f-4e74-8b7b-96d220701d1c",
    "_uuid": "7b7900ba-0d38-4c97-b5e9-0635e237ba3e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df['anatom_site_general_challenge'].where(cond1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4766bdd9-4fe0-42f1-9eb1-4f6ac005df31",
    "_uuid": "17656a4e-9538-4d07-b5b1-44a41d2c635e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(16,8), sharey=True)\n",
    "#train_df['anatom_site_general_challenge'].where(cond1).value_counts()\n",
    "sns.countplot(y=train_df['anatom_site_general_challenge'].where(cond1),ax=ax[0])\n",
    "ax[0].set_title(\"Benign: Anatom site distribution\", pad=10)\n",
    "#train_df['anatom_site_general_challenge'].where(cond2).value_counts()\n",
    "sns.countplot(y=train_df['anatom_site_general_challenge'].where(cond2),ax=ax[1])\n",
    "ax[1].set_title(\"Maglinant: Anatom site distribution\", pad=10)\n",
    "ax[1].label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b6d21f4a-ab38-4793-b221-f6cfc8b107aa",
    "_uuid": "91eb5a67-5511-4583-961b-77be5f68c728"
   },
   "source": [
    "## Insight\n",
    "* ”anatom_site_general_challenge“ represent the position of melanoma on patients. As the two parellel graphs shows, \"torso\" is the part of body which has high potential of maglinant skin cancer compare to other parts. \n",
    "\n",
    "* it seems that the most of melanoma images are locatet at \"head/neck\", but more than 99% of the melanomas are benign in training set.\n",
    "\n",
    "* it should be reminded that some of rows in ”anatom_site_general_challenge“ column is missed (null.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9865322-c87f-4716-a126-a0a9bd57dc98",
    "_uuid": "a0e4dcd8-17d5-488b-9355-af574cec5eaa"
   },
   "source": [
    "## diagnosis and result\n",
    "The last feature column in training dataset is \"diagnosis\" (which is not in test dataset), we will explore the relationship between diagnosis and the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a2ab6c3a-7f61-4dcc-9b96-34874fa269c4",
    "_uuid": "aeee7d8e-35e1-4c69-89c3-fe1f3edd9354",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"total kinds of diagnosis:\", len(train_df['diagnosis'].unique()))\n",
    "print(\"list of diagnosis:\", train_df['diagnosis'].unique())\n",
    "print(\"\\nBenign diagonsis distribution:\\n\", train_df['diagnosis'].where(cond1).value_counts())\n",
    "train_df['diagnosis'].where(cond1).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "888d3e1c-2f5f-4899-9475-48955b859856",
    "_uuid": "549eab07-b4f8-4a18-a4ed-0717fdd16be1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_df['diagnosis'].where(cond2).value_counts())\n",
    "train_df['diagnosis'].where(cond2).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33f5fd77-61b4-4f4f-8845-c2efb802e572",
    "_uuid": "e3006132-e9ae-44c7-b0f7-c8f37c90de0f"
   },
   "source": [
    "## Insight\n",
    "* Well, it seems that all the \"melanona\" is diagnosed as \"malignant\";\n",
    "* In the \"benign\" result, most of the diagnoses are \"unknown\", this does not make any sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a91c36ca-bda3-403f-82ba-3588775fd9e7",
    "_uuid": "7b78cf39-6cc6-4e86-84ff-7a572a0df463"
   },
   "source": [
    "# Shallow learning\n",
    "## Data Propreccessing\n",
    "In this section, we will begin with handling missing values and encoding the category columns:\n",
    "* first step is handling missing values. Since test data also has  missing value, we cannot simply drop all the NaN rows. In this case, we can fill with the most common one;\n",
    "* \"age_approx\" is a numerical column, what we need to do is normalisation, we will use MinMaxScaler to normalise the column\n",
    "* regarding category columns: \"sex\", \"anatom_site_general_challenge\", we have explore that those two columns have correlation with the target diagnose result. we will use different encoding for the two columns:\n",
    "\n",
    "    * \"sex\", is a binary classification, we will use conditional expression to convert boolean results to numerical results;\n",
    "    * \"anatom_site_general_challenge\", only have 6 unique values and those values we think are equally important, so we wil try \"OneHotEncoder\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10ced4d2-78b4-43ec-a9f1-8af0df65fa08",
    "_uuid": "3a9f7a35-8793-4689-95c9-a8c120ffb581"
   },
   "source": [
    "### Training metadata preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f30df95-253f-4360-b169-429ec906dc1c",
    "_uuid": "7278f294-573c-4790-914a-374f2fe7ab1e"
   },
   "outputs": [],
   "source": [
    "### setup training baseline dataframe\n",
    "train_df_baseline = train_df.copy()\n",
    "\n",
    "# randomly select a certain number of samples labelled as \"benign\"\n",
    "def random_selection(df1, df2, k_samples=10000):\n",
    "    random_index = random.sample(df1.index.to_list(), k_samples)\n",
    "    random_df = df1.loc[random_index]\n",
    "    select_df = pd.concat([random_df, df2])\n",
    "    select_df.sort_index(inplace=True)\n",
    "    return select_df\n",
    "\n",
    "malignant_train_df = train_df[cond2]\n",
    "benign_train_df = train_df[cond1]\n",
    "\n",
    "train_df_baseline = random_selection(df1=benign_train_df, df2=malignant_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fb43c142-a6a0-48f6-bc11-f696458c11d2",
    "_uuid": "52b459f0-4dda-4ad3-adee-1ca5ffa8cbb2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# \n",
    "features = [\"sex\", \"age_approx\", \"anatom_site_general_challenge\"]\n",
    "# fill missing values with most frequent value \n",
    "impute = SimpleImputer(strategy='most_frequent')\n",
    "train_df_baseline[features] = impute.fit_transform(train_df_baseline[features])\n",
    "\n",
    "\n",
    "# Encoding category columns\n",
    "# Encoding \"sex\" column\n",
    "train_df_baseline = train_df_baseline.assign(sex_enc=(train_df_baseline.sex == 'male').astype('int'))\n",
    "\n",
    "# Encoding \"anatom_site_general_challenge\" column\n",
    "oneHot_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "oneHot_encoded = oneHot_enc.fit_transform(train_df_baseline['anatom_site_general_challenge'].values.reshape(-1,1))\n",
    "oneHot_df = pd.DataFrame(oneHot_encoded, index=train_df_baseline.index)\n",
    "train_df_baseline = train_df_baseline.join(oneHot_df)\n",
    "\n",
    "# Encoding \"age_approx\" column with LableEncoding \n",
    "# label_enc = LabelEncoder()\n",
    "# label_encoded = label_enc.fit_transform(train_df_baseline['age_approx'])\n",
    "\n",
    "#Normilise new \"age\" column\n",
    "scaler = MinMaxScaler()\n",
    "train_df_baseline['age_enc'] = scaler.fit_transform(train_df_baseline['age_approx'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "print(train_df_baseline.shape)\n",
    "train_df_baseline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa54c662-ca6a-401c-bace-192ace848a61",
    "_uuid": "abde5169-1ffa-4fcc-92a1-dd6d8329f9ca"
   },
   "source": [
    "### test metadata preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b63981cd-6415-4b22-840b-b406cb22220c",
    "_uuid": "09f6a97e-db48-4bd3-872d-143a05f450d2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df_baseline = test_df.copy()\n",
    "test_df_baseline[features] = impute.transform(test_df_baseline[features])\n",
    "\n",
    "test_df_baseline = test_df_baseline.assign(sex_enc=(test_df_baseline.sex == 'male').astype('int'))\n",
    "\n",
    "oneHot_encoded = oneHot_enc.transform(test_df_baseline['anatom_site_general_challenge'].values.reshape(-1,1))\n",
    "oneHot_df = pd.DataFrame(oneHot_encoded, index=test_df_baseline.index)\n",
    "test_df_baseline = test_df_baseline.join(oneHot_df)\n",
    "\n",
    "test_df_baseline['age_enc'] = scaler.transform(test_df_baseline['age_approx'].values.reshape(-1,1))\n",
    "\n",
    "print(test_df_baseline.shape)\n",
    "test_df_baseline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a2aeaa92-bb8a-4c9a-bea7-dc61c2c57ff2",
    "_uuid": "a866e087-def1-4be9-ab62-d4dc61b7a9d7"
   },
   "source": [
    "# data training and prediction\n",
    "\n",
    "* In this section we will try to use only metadata for traning, setup a baseline of result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b65afe79-a5ac-49d4-ab52-f4444d137115",
    "_uuid": "3f05bd29-31a8-4af1-bd8a-34364fabaf98",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### At first, we will use KNN to predict the test dataset \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "baseline_features = train_df_baseline.columns[-8:].to_list()\n",
    "trainX = train_df_baseline[baseline_features]\n",
    "trainY = train_df_baseline['target']\n",
    "testX = test_df_baseline[baseline_features]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "knn.fit(trainX, trainY)\n",
    "knn.predict_proba(testX)\n",
    "#### KNN is not suitable for this compitition because the result is amost binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "82c3f810-ee82-477a-bd0f-f77047cb2b3c",
    "_uuid": "b8c5c4fa-ad8c-452a-90b5-5aebca4f83df",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RandomForest is a baseline of results (submission result 0.679)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "baseline_features = train_df_baseline.columns[-8:].to_list()\n",
    "trainX = train_df_baseline[baseline_features]\n",
    "trainY = train_df_baseline['target']\n",
    "testX = test_df_baseline[baseline_features]\n",
    "\n",
    "rfclass = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfclass.fit(trainX, trainY)\n",
    "rfc_predict = rfclass.predict_proba(testX)[:,1]\n",
    "test_df_baseline['rfc_pred'] = rfc_predict\n",
    "test_df_baseline.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f452e8a5-f902-4722-9dc7-b933b5bca05d",
    "_uuid": "c2aba748-40d0-410a-a465-dfbc4d6079d9"
   },
   "source": [
    "# Deep Learning Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04ae9157-2370-4bb1-9c01-eb877b37187a",
    "_uuid": "49234938-dad2-4a24-ba0e-8a1a0e5c2d44",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_path = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\n",
    "test_path = '/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'\n",
    "\n",
    "train_files = glob.glob(train_path+\"*\") \n",
    "test_files = glob.glob(test_path+\"*\") \n",
    "print('Number of train images: %d \\nNumber of test images:%d' %(len(train_files), len(test_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2652930e-9c83-4ea4-a607-a6e2e4217371",
    "_uuid": "5697370d-af67-4699-9cf4-ca5e7d4034bb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_image, X_val_image, Y_train_image, Y_val_image = train_test_split(train_df_baseline['image_name'], train_df_baseline['benign_malignant'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "48173f4d-9151-4639-bc47-5c1b62cb3b8c",
    "_uuid": "317389de-fcda-48bd-a0ff-2ca8642a4ced",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_df_train = train_df_baseline.loc[X_train_image.index, ['image_name', 'benign_malignant']]\n",
    "image_df_train['image_name'] = image_df_train['image_name'] + '.jpg'\n",
    "image_df_train.sort_index(inplace=True)\n",
    "print(image_df_train.shape)\n",
    "image_df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "640259d7-250a-4101-88c6-e68733bed82a",
    "_uuid": "aca8c476-43fb-488f-869e-b6c8a3708627",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_df_valid = train_df_baseline.loc[X_val_image.index, ['image_name', 'benign_malignant']]\n",
    "image_df_valid['image_name'] = image_df_valid['image_name'] + '.jpg'\n",
    "image_df_valid.sort_index(inplace=True)\n",
    "print(image_df_valid.shape)\n",
    "image_df_valid.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d11a6c52-6f56-4be6-808c-c4748f287981",
    "_uuid": "1ffcb307-d3d2-476e-b5cd-7cbcfacbd44b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_df_test = test_df_baseline[['image_name']] + '.jpg'\n",
    "print(image_df_test.shape)\n",
    "image_df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### from keras.applications import vgg16\n",
    "from keras.applications import mobilenet_v2\n",
    "\n",
    "imageDG = ImageDataGenerator(preprocessing_function=mobilenet_v2.preprocess_input)\n",
    "#imageDG = ImageDataGenerator(rescale=1.0/255)\n",
    "train_batches = imageDG.flow_from_dataframe(dataframe=image_df_train, directory=train_path, x_col='image_name', y_col='benign_malignant', \\\n",
    "                                            target_size=(224,224), classes=['benign', 'malignant'], batch_size=32)\n",
    "\n",
    "valid_batches = imageDG.flow_from_dataframe(dataframe=image_df_valid, directory=train_path, x_col='image_name', y_col='benign_malignant', \\\n",
    "                                            target_size=(224,224), classes=['benign', 'malignant'], batch_size=32)\n",
    "\n",
    "test_batches = imageDG.flow_from_dataframe(dataframe=image_df_test, directory=test_path, x_col='image_name', \\\n",
    "                                           target_size=(224,224), shuffle=False, classes=None, class_mode=None, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f7c1709b-0881-4332-a969-9be8decb53b6",
    "_uuid": "49830040-9218-466e-8eaa-af0a2c55bb30"
   },
   "source": [
    "### Here we have already generated the train, valid and test batches for CNN training, validating and prediction, notice that we use the preprocessing function from vgg16, we will use the pre-trained vgg16 module to build our image training model (vgg16 paper: https://arxiv.org/pdf/1409.1556.pdf).\n",
    "### Before building the model, we will first ensure that our image can be plotted correctly, the plotImages function is directly copy from Tensorflow documentation: https://www.tensorflow.org/tutorials/images/classification#visualize_training_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "951dfee0-9b63-4ab9-a469-4a233e65b660",
    "_uuid": "3f68d279-97bf-4d19-aa68-14939aefbf09",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "875645af-b970-45f4-ba94-86843449611c",
    "_uuid": "ea193630-1828-4509-bd38-fd422707e8ce",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs, labels= next(train_batches)\n",
    "plotImages(imgs)\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7367235e-15d1-4b64-a311-e1f1eee8cd21",
    "_uuid": "d8240405-b432-4b3b-bf4d-5d27b45b9986",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs, labels= next(valid_batches)\n",
    "plotImages(imgs)\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ffa33ae2-43e3-4b81-9f24-ce351ca9b3ff",
    "_uuid": "a06f1ad1-ef81-44ba-814c-204be7b7a350",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs= next(test_batches)\n",
    "plotImages(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a768eb0e-06e3-42c4-8ed0-f3bfface3aa8",
    "_uuid": "9f7fda9a-f2f1-403e-b5e5-8da370740688"
   },
   "source": [
    "## Insight\n",
    "* Well, we are not doctors, we cann't identify whether the melanoma shown in each image is benign or malignant;\n",
    "* However, we can ensure that we are on the right path: all the image load in generator and no images left, the train images have been seperated into training and validation sets and then can be used for training and validation, the batches of images in three sets can be plotted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c5c5a795-e6c9-4c27-85d5-a8c4f2f21900",
    "_uuid": "0ecb070f-0582-42cd-a7fb-27b4c40d2f5d"
   },
   "source": [
    "# Deep Learning Model\n",
    "\n",
    "* As we mentioned above, we will use the exist MobileNetV2 model to build our own model to reduce the training time and also the model is a pre-trained model have many layers and tuned parameters which are much better than simple CNN model build from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dd8ba0ce-66f7-45ed-84a5-4ee5956969d5",
    "_uuid": "87ad16df-0cbf-43e6-ab39-275ff7e02314",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.applications import mobilenet\n",
    "# mobile = mobilenet.MobileNet()\n",
    "# mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0ad6f31b-2100-463a-a08f-059285468955",
    "_uuid": "6150a26f-fece-487c-8061-37e010e70d13",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mobile = mobilenet_v2.MobileNetV2()\n",
    "print(\"type of mobilenet_v2 model:\", type(mobile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #transfer learning\n",
    "# from keras import Model\n",
    "# model = Sequential()\n",
    "# for layer in mobile.layers[:-1]:\n",
    "#     model.add(layer)\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.add(Dense(units=2, activation='softmax'))\n",
    "# model.summary()\n",
    "\n",
    "#transfer learning\n",
    "from keras import Model\n",
    "output = Dense(units=2, activation='softmax')(mobile.layers[-2].output)\n",
    "model = Model(inputs=mobile.input, outputs=output)\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b999af32-b96d-4fc8-9dd3-ea9252e6bac4",
    "_uuid": "de0c6133-ad5b-4b93-8495-92cc6efcbed9"
   },
   "source": [
    "* Since the orignal vgg16 model has 1000 final ouput, which obviously is not suitable for us (we only have two), we will substitute our own layer for the last layer of vgg16 model.\n",
    "* To achive the purpose, we will duplicate vgg16 model expect the last layer.\n",
    "* Notice that the pre-trained parameters will be set as \"not trainable\", which means, the parameters will not be tuned while training our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7d8b16d9-cfaf-472f-ae38-5777354aa19e",
    "_uuid": "ae0dd904-af8d-4a9c-83c4-26da620cf472",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check if GPU is available to use for tensorflow\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01742425-2251-4c28-972f-fd3ff3594047",
    "_uuid": "8ccab367-7eb5-42da-9a73-0389ff1d0b8c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit_generator(train_batches, validation_data=valid_batches, epochs=2, \\\n",
    "                                   steps_per_epoch=len(train_batches), validation_steps=len(valid_batches), \\\n",
    "                                   workers=mp.cpu_count(), use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b02258ef-ddce-4b98-b8a8-1646c3b1bcb1",
    "_uuid": "25571635-4f5d-4fcb-84a8-487cb90b5d70"
   },
   "outputs": [],
   "source": [
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers import ZeroPadding2D\n",
    "# from keras.layers import InputLayer\n",
    "# from keras.layers import ReLU\n",
    "\n",
    "# def CNN_model(input_shape=(48,48,3)):\n",
    "#     model = Sequential()\n",
    "#     # first Convolution layer, first time need input_shape, valid faster and better \n",
    "#     model.add(InputLayer(input_shape=(48,48,3)))\n",
    "#     model.add(ZeroPadding2D(padding=((1,0),(1,0))))\n",
    "#     model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     # second Convolution layer\n",
    "#     model.add(Conv2D(64, (3, 3), padding='valid', activation='relu', strides=1,))\n",
    "#     # second MaxPooling layer\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     # third Convolution layer\n",
    "#     model.add(Conv2D(128, (3, 3), padding='valid', activation='relu', strides=1,))\n",
    "#     # third MaxPooling layer\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     # Flatten\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(units = 256, activation='relu', name=\"Dense_1\"))\n",
    "#     model.add(Dense(units = 2, activation='softmax'))\n",
    "    \n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     model.fit_generator(train_batches, validation_data=valid_batches, epochs=2, \\\n",
    "#                                    steps_per_epoch=len(train_batches), validation_steps=len(valid_batches), \\\n",
    "#                                    workers=mp.cpu_count(), use_multiprocessing=True, verbose=1)\n",
    "#     model.summary()\n",
    "#     return model\n",
    "\n",
    "# input_model = CNN_model()\n",
    "# feature_model = Model(inputs=input_model.input, outputs=model.get_layer(index=-2).output)\n",
    "# for layer in feature_model.layers[:-1]:\n",
    "#     layer.trainable = False\n",
    "# feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "00e0da21-b97b-4498-869b-d92db05e23b8",
    "_uuid": "e31af602-ad98-4dcd-91cb-c5ef00376201",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_feature_train = model.predict(train_batches, workers=mp.cpu_count(), use_multiprocessing=True, verbose=1)\n",
    "print(image_feature_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c62745b3-71ad-4a96-9627-8e2404d6285f",
    "_uuid": "06122191-8f92-46f9-bca8-ca7c8b19c945",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_feature_valid = model.predict(valid_batches, workers=mp.cpu_count(), use_multiprocessing=True, verbose=1)\n",
    "print(image_feature_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3fcacd39-9d5a-4a49-966c-e4ae867fcd1b",
    "_uuid": "fe9056f5-a437-4c73-aa98-c9810f691cdc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_feature_test = model.predict(test_batches, workers=mp.cpu_count(), use_multiprocessing=True, verbose=1)\n",
    "print(image_feature_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "733fd8ac-631b-43fd-b1f4-864647226eea",
    "_uuid": "2a7cea9f-ff24-415d-95cb-9013955f3314",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = [f'imft_{num}' for num in range(image_feature_train.shape[1])]\n",
    "train_feature_df = pd.DataFrame(image_feature_train, columns=cols, index=image_df_train.index)\n",
    "valid_feature_df = pd.DataFrame(image_feature_valid, columns=cols, index=image_df_valid.index)\n",
    "test_feature_df = pd.DataFrame(image_feature_test, columns=cols, index=image_df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "81b91bbb-eb6f-47ea-b241-c84df632f1c3",
    "_uuid": "8e8ed9e3-f3ad-4e34-9774-9a6f6e6eb17c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_X_final = pd.concat([train_feature_df,train_df_baseline.loc[image_df_train.index, baseline_features]], axis=1)\n",
    "valid_X_final = pd.concat([valid_feature_df,train_df_baseline.loc[image_df_valid.index, baseline_features]], axis=1)\n",
    "test_X_final = pd.concat([test_feature_df,test_df_baseline.loc[image_df_test.index, baseline_features]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "607eab08-dcaf-4f6e-9c69-b2595075eacb",
    "_uuid": "c23f75c0-f9a1-4b98-b356-fdd4c0456f1b"
   },
   "outputs": [],
   "source": [
    "image_df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "16ec683a-7576-4cda-989c-57672087f51d",
    "_uuid": "36b074b5-adde-4cea-9012-7e3d67e8fcca"
   },
   "outputs": [],
   "source": [
    "train_df_baseline.loc[image_df_train.index, baseline_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a0baa2b7-ff9f-4b7a-a93f-85f639082179",
    "_uuid": "7bdb2eec-0298-40b3-8b4d-3af99ca9bd60"
   },
   "outputs": [],
   "source": [
    "train_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0d9c2ce-c1d3-430c-afa9-8b01ee3df5e9",
    "_uuid": "eac6ec47-f009-462f-9247-13731967d810",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "dtrain = lgb.Dataset(data=train_X_final, label=train_df_baseline.loc[image_df_train.index, 'target'])\n",
    "dvalid = lgb.Dataset(data=valid_X_final, label=train_df_baseline.loc[image_df_valid.index, 'target'])\n",
    "\n",
    "param = {'num_leaves': 64, 'objective': 'binary', 'metric': 'auc'}\n",
    "num_boost_round = 1000\n",
    "\n",
    "bst = lgb.train(param, dtrain, num_boost_round, dvalid, early_stopping_rounds=10, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d2dbf61b-8d2d-416b-b072-8920acc51856",
    "_uuid": "27afe9ac-8a59-4d4d-b798-660f08aa454d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "939c3647-d4da-4d86-92bf-a15e727f6f04",
    "_uuid": "ebba297d-5409-4ccf-b8de-23170630f8ca",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_pred = bst.predict(test_X_final)\n",
    "test_df_baseline['lgb_pred'] = target_pred\n",
    "#compare the first few rows of predict results between RandomForest and CNN+LGB \n",
    "test_df_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40ff2faa-fdaf-4a68-a60a-c4450bc4580c",
    "_uuid": "945b3f77-0a3d-4e4e-bf67-513a21d8f342",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In case the order of \"image_name\" in sample_submission.csv is not the same as in test.csv \n",
    "ss = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv\")\n",
    "ss = ss.merge(test_df_baseline[['image_name', 'lgb_pred']], on='image_name')\n",
    "\n",
    "upload = ss[['image_name', 'lgb_pred']]\n",
    "upload.columns = ['image_name', 'target']\n",
    "\n",
    "\n",
    "upload.to_csv('submission.csv', index=False)\n",
    "upload.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1af9e25c-c93b-4a21-b511-f62c6cd0f23e",
    "_uuid": "85e74e38-cd23-4617-85f1-b54bcee63bd7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
